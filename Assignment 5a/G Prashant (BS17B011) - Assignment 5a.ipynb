{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Classification : Nearest Neighbors and Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Perform k-Nearest neighbours on the given dataset($X_{knn}$ and $y_{knn}$: where $X_{knn}$ stores feature vectors representing the movies and  $y_{knn}$ stores the 0-1 labelling for each movie) for binary classification of movies, for classifiying whether a given movie is a comedy(label 1) or not a comedy(label 0) . Split the dataset into train(80%), validation(10%) and test sets(10%).Run k-Nearest neighbours for different k values (1,3,7,15,31,63). Select the k, using validation set, which returns the best accuracy score. \n",
    "\n",
    "(i)  Report all the validation accuracies for all the values of k. \n",
    "<br>(ii) Report accuracy score by performing k-NN on the test dataset using the best chosen k value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading dataset\n",
    "X_knn = pd.read_csv(\"X_knn.csv\",header=None,sep=\" \")\n",
    "y_knn = pd.read_csv(\"y_knn.csv\",header = None).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Validation, Test set splittings\n",
    "np.random.seed(20)\n",
    "X_train_and_val,X_test, y_train_and_val, y_test = train_test_split(X_knn,y_knn,train_size = 0.9, test_size = 0.1,shuffle = True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_and_val,y_train_and_val,test_size = 1/9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dist(X_new,X):\n",
    "    \"\"\"\n",
    "    Function to compute distance matrix\n",
    "    X_new: Dataset to perform prediction on\n",
    "    X: Training dataset\n",
    "    Returns -\n",
    "    dist_array: Distance matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    (m_new,n_new) = X_new.shape\n",
    "    (m,n) = X.shape\n",
    "    \n",
    "    dist_array = np.zeros((m_new,m))\n",
    "    \n",
    "    for i in range(m_new):\n",
    "        for j in range(m):\n",
    "            dist = np.linalg.norm(X_new[i,:]-X[j,:])\n",
    "            dist_array[i,j] = dist\n",
    "    return dist_array\n",
    "\n",
    "def predict_knn(dist_array,X_new,y,k):\n",
    "    \"\"\"\n",
    "    Function to predict the label of a new data point using kNN\n",
    "    Returns - \n",
    "    y_pred: perdicted class label vector\n",
    "    \"\"\"\n",
    "    (m,n) = X_new.shape\n",
    "    y_pred = np.zeros((m,1))\n",
    "    \n",
    "    for i in range(m):\n",
    "        index = np.argsort(dist_array[i][:])\n",
    "        pos = 0\n",
    "        #Noting the labels of k-Nearest neighbours\n",
    "        for near in range(k):\n",
    "            if y[index[near]][0]==1:\n",
    "                pos+=1\n",
    "        if pos>k-pos:\n",
    "            y_pred[i] = 1\n",
    "        else:\n",
    "            y_pred[i] = 0\n",
    "            \n",
    "    return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN with k = 1\n",
      "Cross-Validation Accuracy: 0.797\n",
      "\n",
      "kNN with k = 3\n",
      "Cross-Validation Accuracy: 0.840\n",
      "\n",
      "kNN with k = 7\n",
      "Cross-Validation Accuracy: 0.858\n",
      "\n",
      "kNN with k = 15\n",
      "Cross-Validation Accuracy: 0.865\n",
      "\n",
      "kNN with k = 31\n",
      "Cross-Validation Accuracy: 0.862\n",
      "\n",
      "kNN with k = 63\n",
      "Cross-Validation Accuracy: 0.854\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Accuracy vs number of nearest neighbors k')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Training the model with different k-values\n",
    "k_values = [1,3,7,15,31,63]\n",
    "cv_scores = []\n",
    "models = []\n",
    "\n",
    "dist_array = compute_dist(np.array(X_val),np.array(X_train))\n",
    "for k in k_values:\n",
    "    print(\"kNN with k = %d\"%k)\n",
    "    \n",
    "    #Prediction on validation dataset\n",
    "    y_hat_val = predict_knn(dist_array,np.array(X_val),np.array(y_train),k)\n",
    "    cv_acc = np.sum(y_hat_val==y_val)[0]/len(y_val)\n",
    "    print(\"Cross-Validation Accuracy: %0.3f\"%cv_acc,end = \"\\n\\n\")\n",
    "    cv_scores.append(cv_acc)\n",
    "\n",
    "#Storing best k-value\n",
    "k_best = k_values[cv_scores.index(max(cv_scores))]\n",
    "\n",
    "#Plotting \n",
    "plt.figure()\n",
    "plt.plot(k_values,cv_scores,\"-o\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Cross-Validation Accuracy\")\n",
    "plt.title(\"Validation Accuracy vs number of nearest neighbors k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can notice that $k=15$ gives the highest cross-validation accuracy of 0.865**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the best model on the test dataset = 0.846\n"
     ]
    }
   ],
   "source": [
    "#Evalutating the trained model on the test set with best value of k\n",
    "dist_array_test = compute_dist(np.array(X_test),np.array(X_train))\n",
    "y_hat_test = predict_knn(dist_array_test,np.array(X_test),np.array(y_train),k_best)\n",
    "#Calculating accuracy\n",
    "test_acc = np.sum(y_hat_test==y_test)[0]/len(y_test)\n",
    "\n",
    "print(\"Accuracy of the best model on the test dataset = %0.3f\"%test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) State why using an even value of k in k-NN should not be chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-Nearest Neighbors algorithm works on the assumption that data points that are closer in distance are similar. Precisely, if we want to predict the class of a given data point, we observe the class labels of the k nearest (in distance) neighbours. We assign the label to the data point based on the majority of the labels of k nearest neighbors. \n",
    "\n",
    "In this regard, considering binary classification, if $k$ is even, there are chances that $k/2$ neighbors are labeled as one class (say class $1$) and the remaining $k/2$ neighbors are labeled the other (class $0$). This results in a tie as no class is the majority among the neighbours, and hence it becomes difficult to assign a label to the data point. To bypass this issue, it is recommended to choose an odd value of k.\n",
    "\n",
    "In datasets involving multiple classes (more than 2), such situations are more prone to occur even if $k$ is not even."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Naive Bayes' classifier  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Continuous Distribution of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the distribution of the data( $X$ represents the datapoints and $Y$ represents the 0-1 binary-class label; where 0 being the negative class and 1 being the positive class) is already known.\n",
    "<br>Consider the following one-dimensional(1-D) Gaussian distributions where means and variances are unknown. You need to estimate means($\\mu_-$: for negative class and  $\\mu_+$: for positive class) and variances ($\\sigma^{2}_{-}$: for negative class and $\\sigma^{2}_+$: for positive class) from the given data : \n",
    "<br> (1) Assume $X|Y_{Y=0} \\sim \\mathcal{N}(\\mu_- , \\sigma^{2}_-)$ \n",
    "<br>(2) Assume $X|Y_{Y=1} \\sim \\mathcal{N}(\\mu_+ , \\sigma^{2}_+)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Generating artificial datasets in the next cell *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell is for generating datasets. Students should not change anything in this cell. \n",
    "## You can compare your mean and variance estimates by the actual ones used to generate these datasets\n",
    "\n",
    "import numpy as np\n",
    "X_pos = np.random.randn(1000,1)+np.array([[2.]])\n",
    "X_neg = np.random.randn(1000,1)+np.array([[4.]])\n",
    "X_train_pos = X_pos[:900]\n",
    "X_train_neg = X_neg[:900]\n",
    "X_test_pos = X_pos[900:]\n",
    "X_test_neg = X_neg[900:]\n",
    "X_train = np.concatenate((X_train_pos, X_train_neg), axis=0)\n",
    "X_test = np.concatenate((X_test_pos, X_test_neg), axis=0)\n",
    "Y_train = np.concatenate(( np.ones(900),np.zeros(900) ))\n",
    "Y_test = np.concatenate(( np.ones(100), np.zeros(100) ))\n",
    "\n",
    "## X_train, X_test, Y_train, Y_test are your datasets to work with ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<br>**Instructions to follow for learning a Baeysian classifier:** *(Code the formulae for estimating the different parameters yourself)*\n",
    "<br> a)Utilize the training dataset to estimate the means($\\hat{\\mu_+}$,$\\hat{\\mu_-}$) and variances($\\hat{\\sigma^{2}_+}$, $\\hat{\\sigma^{2}_-}$) for both positive and negative classes  \n",
    "b)Estimate the prior probability: $P(Y=1)$  ⟶ which could be referred to as: $\\hat{a}$ \n",
    "<br>c)Estimate the classifier funtion/posterior probability:  $P(Y=1|X = x)$  ⟶ which could be referred to as $\\hat{\\eta(x)}$\n",
    "<br>d)Find out the threshold value($x^*$) for classification by equating the estimated classifier function($\\hat{\\eta(x)}$)  with threshold probability of 0.5\n",
    "<br>e)Classify the test dataset into the two classes using this threshold value($x^*$) and find out the **accuracy** of the prediction \n",
    "\n",
    "Return back:  $\\hat{\\mu_+}$, $\\hat{\\mu_-}$, $\\hat{\\sigma^{2}_+}$, $\\hat{\\sigma^{2}_-}$, $\\hat{a}$, $x^*$ and accuracy from the code written \n",
    "\n",
    "*Hint: $X|Y_{Y=0} \\sim \\mathcal{N}(\\mu_- , \\sigma^{2}_-)$ implies $P_{X|Y=0} = \\mathcal{N}(\\mu_- , \\sigma^{2}_-) $*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training Naive Bayes Algorithm\n",
    "# Estimating prior probabilities from training data\n",
    "(m,n) = X_train.shape\n",
    "prior_1 = np.sum(Y_train==1)/m  #a_cap = p(Y=1)\n",
    "prior_0 = 1-prior_1\n",
    "\n",
    "gauss = lambda x,mu,sig: (1/(np.sqrt(2*np.pi)*sig)) * np.exp(-((x-mu)**2)/(2*sig**2))\n",
    "\n",
    "# Estimating parameters of Gaussian distribution for each class\n",
    "mu_class0 = np.mean(X_train[Y_train==0])\n",
    "mu_class1 = np.mean(X_train[Y_train==1])\n",
    "\n",
    "std_class0 = np.std(X_train[Y_train==0])\n",
    "std_class1 = np.std(X_train[Y_train==1])\n",
    "\n",
    "#Evaluating likelihoods of the training data for each class\n",
    "class_probab_0 = gauss(X_train,mu_class0,std_class0)*prior_0\n",
    "class_probab_1 = gauss(X_train,mu_class1,std_class1)*prior_1\n",
    "\n",
    "#Evaluating posterior probabilities of the training data for each class\n",
    "posterior_class0 = class_probab_0/(class_probab_0+class_probab_1)\n",
    "posterior_class1 = class_probab_1/(class_probab_0+class_probab_1)\n",
    "\n",
    "#Training set predictions\n",
    "Y_pred_train = (posterior_class1>0.5).astype(int)\n",
    "\n",
    "#Determining training accuracy\n",
    "train_acc = np.mean(Y_pred_train == Y_train.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9547133896235733,\n",
       " 4.047271149433509,\n",
       " 0.9409209740987953,\n",
       " 0.9352267651153012,\n",
       " 0.5)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_class1, mu_class0, std_class1**2, std_class0**2, prior_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{\\mu_+} = 1.9547$$\n",
    "$$\\hat{\\mu_-} = 4.0473$$\n",
    "$$\\hat{\\sigma^{2}_+} = 0.94092$$\n",
    "$$\\hat{\\sigma^{2}_-} = 0.93523$$\n",
    "$$\\hat{a} = 0.5$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the classifier/posterior PDF function (upon cancelling the prior and normalisation terms) is $$P(Y=1|X=x) = \\hat{\\eta}(x) = \\frac{\\frac{1}{\\sigma_+}e^{-\\frac{(x-\\mu_+)^2}{2\\sigma^{2}_+}}}{\\frac{1}{\\sigma_+}e^{-\\frac{(x-\\mu_+)^2}{2\\sigma^{2}_+}} + \\frac{1}{\\sigma_-}e^{-\\frac{(x-\\mu_-)^2}{2\\sigma^{2}_-}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{\\eta}(X_{train})$ is given blow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.885333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.554934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.701000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.328543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.832632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.003395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.197703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>0.011511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>0.025318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>0.169666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     0.885333\n",
       "1     0.554934\n",
       "2     0.701000\n",
       "3     0.328543\n",
       "4     0.832632\n",
       "...        ...\n",
       "1795  0.003395\n",
       "1796  0.197703\n",
       "1797  0.011511\n",
       "1798  0.025318\n",
       "1799  0.169666\n",
       "\n",
       "[1800 rows x 1 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(posterior_class1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equating $\\hat{\\eta}(x) = P(Y=1) = 0.5$, we can reframe it to solving the roots of:\n",
    "\n",
    "$$(\\frac{1}{2\\hat{\\sigma^{2}_+}} - \\frac{1}{2\\hat{\\sigma^{2}_-}})x^2 + (\\frac{\\mu_-}{\\hat{\\sigma^{2}_-}} - \\frac{\\mu_+}{\\hat{\\sigma^{2}_+}})x + \\frac{\\mu_+^2}{\\hat{2\\sigma^{2}_+}} - \\frac{\\mu_-^2}{2\\hat{\\sigma^{2}_-}} - \\ln(\\frac{\\sigma_-}{\\sigma_+}) = 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mathematically determining x* by solving the quadratic equation\n",
    "a = (1/(2*std_class1**2) - 1/(2*std_class0**2))\n",
    "b = (mu_class0/(std_class0**2) - mu_class1/(std_class1**2))\n",
    "c = (mu_class1**2/(2*std_class1**2) - mu_class0**2/(2*std_class0**2)) - np.log(std_class0/std_class1)\n",
    "\n",
    "x_star = (-b + np.sqrt(b**2-4*a*c))/(2*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.001219448352256"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence $$x^* = 3.00122$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, if $x>x^*$, $Y$ is more likely to be $0$ and if $x<x^*$, $Y$ is more likely to be $1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.860000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy: %f\"%train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifying the test dataset based on the obtained threshold x*\n",
    "\n",
    "m_test = X_test.shape[0]\n",
    "\n",
    "Y_pred_test = np.zeros((m_test,1))\n",
    "#Values less than the threshold are labelled 1\n",
    "Y_pred_test[X_test<=x_star] = 1\n",
    "\n",
    "test_acc = np.mean(Y_pred_test == Y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.800000\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy: %f\"%test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Discrete distribution of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the first exercise for learning the Naive Bayes' classifier where we dealt with continuous distribution of data, here you need to work with discrete data, which means finding Probability Mass Distribution(PMF). \n",
    "\n",
    "Age  | Income | Status  | Buy\n",
    "-----|--------|-------- |----\n",
    "<=20 |  low   | students| yes\n",
    "<=20 |  high  | students| yes\n",
    "<=20 | medium | students| no\n",
    "<=20 | medium | married | no\n",
    "<=20 |  high  | married | yes\n",
    "21-30|  low   | married | yes\n",
    "21-30|  low   | married | no \n",
    "21-30| medium | students| no\n",
    "21-30|  high  | students| yes\n",
    " >30 |  high  | married | no\n",
    " >30 |  high  | married | yes\n",
    " >30 | medium | married | yes\n",
    " >30 | medium | married | no\n",
    " >30 | medium | students| no\n",
    " \n",
    "Consider the train dataset above. Take any random datapoint ($X_{i}$) where $X_{i} = (X_{i,1} = Age,X_{i,2} = Income,X_{i,3} = Status)$ and its corresponding label \n",
    "\n",
    "($Y_{i} = Buy$). A \"yes\" in Buy corresponds to label-1 and a \"no\" in Buy corresponds to label-0.\n",
    "\n",
    "<br>**Instructions to follow for learning a Baeysian classifier:** *(Code the formulae for estimating the different parameters yourself)*\n",
    "<br> a)Estimate the prior probability: $P(Y=1)$  ⟶ which could be referred to as: $\\hat{a}$   \n",
    "b)Estimate the likelihood for each feature:  $P(X_{i,j} = x |Y = y_{i})$, where $ i$=datapoint counter, $j \\in \\{1,2,3\\}$ and $y_{i} \\in \\{0,1\\}$ \n",
    "<br>c)Estimate the total likelihood: $P(X_{i} = x |Y = y_{i})$  \n",
    "d)Calculate the posterior probability: $P(Y = 1|X_{i} = x_{test} )$ = $p_{test}$ where $x_{test} = (Age = 21-30, Income= medium, Status = married)$\n",
    "\n",
    "\n",
    "Return back: $\\hat{a}$, total likelihood and $p_{test}$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part (a) - Estimating prior, P(Y=1)\n",
    "\n",
    "#a_cap = P(Y=1)\n",
    "prior_buy = 7/14\n",
    "#P(Y=0)\n",
    "prior_nobuy = 1- prior_buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(prior_buy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{a} = P(Y=1) = 0.5$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part (b) - Likelihood of each feature \n",
    "\n",
    "## Feature - Age\n",
    "#P(X_i_1 = \"<=20\"/Y=1)\n",
    "p_lt20_buy = 3/7\n",
    "#P(X_i_1 = \"21 to 30\"/Y=1)\n",
    "p_21to30_buy = 2/7\n",
    "#P(X_i_1 = \">30\"/Y=1)\n",
    "p_gt30_buy = 1-p_lt20_buy-p_21to30_buy\n",
    "\n",
    "#P(X_i_1 = \"<=20\"/Y=0)\n",
    "p_lt20_nobuy = 2/7\n",
    "#P(X_i_1 = \"21 to 30\"/Y=0)\n",
    "p_21to30_nobuy = 2/7\n",
    "#P(X_i_1 = \">30\"/Y=0)\n",
    "p_gt30_nobuy = 1-p_lt20_nobuy-p_21to30_nobuy\n",
    "\n",
    "## Feature - Income\n",
    "#P(X_i_2 = high/Y=1)\n",
    "p_high_buy = 4/7\n",
    "#P(X_i_2 = medium/Y=1)\n",
    "p_medium_buy = 1/7\n",
    "#P(X_i_2 = low/Y=1)\n",
    "p_low_buy = 1-p_high_buy-p_medium_buy\n",
    "\n",
    "#P(X_i_2 = high/Y=0)\n",
    "p_high_nobuy = 1/7\n",
    "#P(X_i_2 = medium/Y=0)\n",
    "p_medium_nobuy = 5/7\n",
    "#P(X_i_2 = low/Y=0)\n",
    "p_low_nobuy = 1-p_high_nobuy-p_medium_nobuy\n",
    "\n",
    "## Feature - Status\n",
    "#P(X_i_3 = students/Y=1)\n",
    "p_students_buy = 3/7\n",
    "#P(X_i_3 = married/Y=1)\n",
    "p_married_buy = 1-p_students_buy\n",
    "\n",
    "#P(X_i_3 = students/Y=0)\n",
    "p_students_nobuy = 3/7\n",
    "#P(X_i_3 = married/Y=0)\n",
    "p_married_nobuy = 1 - p_students_nobuy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j=1,2,3 represent features Age, Income and Status, respectively\n",
      "\n",
      "Y=1 represents bought, and Y=0 represents not bought\n",
      "\n",
      "P(X_{i1}= '<=20'|Y=1) = 0.428571\n",
      "P(X_{i1}= '21 to 30'|Y=1) = 0.285714\n",
      "P(X_{i1}= '>30'|Y=1) = 0.285714\n",
      "P(X_{i1}= '<=20'|Y=0) = 0.285714\n",
      "P(X_{i1}= '21 to 30'|Y=0) = 0.285714\n",
      "P(X_{i1}= '>30'|Y=0) = 0.428571\n",
      "\n",
      "P(X_{i2}= 'low'|Y=1) = 0.285714\n",
      "P(X_{i2}= 'medium'|Y=1) = 0.142857\n",
      "P(X_{i2}= 'high'|Y=1) = 0.571429\n",
      "P(X_{i2}= 'low'|Y=0) = 0.142857\n",
      "P(X_{i2}= 'medium'|Y=0) = 0.714286\n",
      "P(X_{i2}= 'high'|Y=0) = 0.142857\n",
      "\n",
      "P(X_{i3}= 'student'|Y=1) = 0.428571\n",
      "P(X_{i3}= 'married'|Y=1) = 0.571429\n",
      "P(X_{i3}= 'student'|Y=0) = 0.428571\n",
      "P(X_{i3}= 'married'|Y=0) = 0.571429\n"
     ]
    }
   ],
   "source": [
    "print(\"j=1,2,3 represent features Age, Income and Status, respectively\\n\")\n",
    "print(\"Y=1 represents bought, and Y=0 represents not bought\\n\")\n",
    "print(\"P(X_{i1}= '<=20'|Y=1) = %f\"%p_lt20_buy)\n",
    "print(\"P(X_{i1}= '21 to 30'|Y=1) = %f\"%p_21to30_buy)\n",
    "print(\"P(X_{i1}= '>30'|Y=1) = %f\"%p_gt30_buy)\n",
    "print(\"P(X_{i1}= '<=20'|Y=0) = %f\"%p_lt20_nobuy)\n",
    "print(\"P(X_{i1}= '21 to 30'|Y=0) = %f\"%p_21to30_nobuy)\n",
    "print(\"P(X_{i1}= '>30'|Y=0) = %f\"%p_gt30_nobuy)\n",
    "print(\"\")\n",
    "print(\"P(X_{i2}= 'low'|Y=1) = %f\"%p_low_buy)\n",
    "print(\"P(X_{i2}= 'medium'|Y=1) = %f\"%p_medium_buy)\n",
    "print(\"P(X_{i2}= 'high'|Y=1) = %f\"%p_high_buy)\n",
    "print(\"P(X_{i2}= 'low'|Y=0) = %f\"%p_low_nobuy)\n",
    "print(\"P(X_{i2}= 'medium'|Y=0) = %f\"%p_medium_nobuy)\n",
    "print(\"P(X_{i2}= 'high'|Y=0) = %f\"%p_high_nobuy)\n",
    "print(\"\")\n",
    "print(\"P(X_{i3}= 'student'|Y=1) = %f\"%p_students_buy)\n",
    "print(\"P(X_{i3}= 'married'|Y=1) = %f\"%p_married_buy)\n",
    "print(\"P(X_{i3}= 'student'|Y=0) = %f\"%p_students_buy)\n",
    "print(\"P(X_{i3}= 'married'|Y=0) = %f\"%p_married_nobuy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part (c) -Estimating total likelihoods of all feature combinations, for class 1\n",
    "\n",
    "#P(X_i = \"\"<=20\",\"low\",\"students\"\"/Y=1)\n",
    "p_lt20_low_students_buy = p_lt20_buy*p_low_buy*p_students_buy\n",
    "#P(X_i = \"\"<=20\",\"low\",\"married\"\"/Y=1)\n",
    "p_lt20_low_married_buy = p_lt20_buy*p_low_buy*p_married_buy\n",
    "#P(X_i = \"\"<=20\",\"medium\",\"students\"\"/Y=1)\n",
    "p_lt20_medium_students_buy = p_lt20_buy*p_medium_buy*p_students_buy\n",
    "#P(X_i = \"\"<=20\",\"medium\",\"married\"\"/Y=1)\n",
    "p_lt20_medium_married_buy = p_lt20_buy*p_medium_buy*p_married_buy\n",
    "#P(X_i = \"\"<=20\",\"high\",\"students\"\"/Y=1)\n",
    "p_lt20_high_students_buy = p_lt20_buy*p_high_buy*p_students_buy\n",
    "#P(X_i = \"\"<=20\",\"high\",\"married\"\"/Y=1)\n",
    "p_lt20_high_married_buy = p_lt20_buy*p_high_buy*p_married_buy\n",
    "\n",
    "#P(X_i = \"\"21 to 30\",\"low\",\"students\"\"/Y=1)\n",
    "p_21to30_low_students_buy = p_21to30_buy*p_low_buy*p_students_buy\n",
    "#P(X_i = \"\"21 to 30\",\"low\",\"married\"\"/Y=1)\n",
    "p_21to30_low_married_buy = p_21to30_buy*p_low_buy*p_married_buy\n",
    "#P(X_i = \"\"21 to 30\",\"medium\",\"students\"\"/Y=1)\n",
    "p_21to30_medium_students_buy = p_21to30_buy*p_medium_buy*p_students_buy\n",
    "#P(X_i = \"\"21 to 30\",\"medium\",\"married\"\"/Y=1)\n",
    "p_21to30_medium_married_buy = p_21to30_buy*p_medium_buy*p_married_buy\n",
    "#P(X_i = \"\"21 to 30\",\"high\",\"students\"\"/Y=1)\n",
    "p_21to30_high_students_buy = p_21to30_buy*p_high_buy*p_students_buy\n",
    "#P(X_i = \"\"21 to 30\",\"high\",\"married\"\"/Y=1)\n",
    "p_21to30_high_married_buy = p_21to30_buy*p_high_buy*p_married_buy\n",
    "\n",
    "#P(X_i = \"\">30\",\"low\",\"students\"\"/Y=1)\n",
    "p_gt30_low_students_buy = p_gt30_buy*p_low_buy*p_students_buy\n",
    "#P(X_i = \"\">30\",\"low\",\"married\"\"/Y=1)\n",
    "p_gt30_low_married_buy = p_gt30_buy*p_low_buy*p_married_buy\n",
    "#P(X_i = \"\">30\",\"medium\",\"students\"\"/Y=1)\n",
    "p_gt30_medium_students_buy = p_gt30_buy*p_medium_buy*p_students_buy\n",
    "#P(X_i = \"\">30\",\"medium\",\"married\"\"/Y=1)\n",
    "p_gt30_medium_married_buy = p_gt30_buy*p_medium_buy*p_married_buy\n",
    "#P(X_i = \"\">30\",\"high\",\"students\"\"/Y=1)\n",
    "p_gt30_high_students_buy = p_gt30_buy*p_high_buy*p_students_buy\n",
    "#P(X_i = \"\">30\",\"high\",\"married\"\"/Y=1)\n",
    "p_gt30_high_married_buy = p_gt30_buy*p_high_buy*p_married_buy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part (c) -Estimating total likelihoods of all feature combinations, for class 0\n",
    "\n",
    "#P(X_i = \"\"<=20\",\"low\",\"students\"\"/Y=0)\n",
    "p_lt20_low_students_nobuy = p_lt20_nobuy*p_low_nobuy*p_students_nobuy\n",
    "#P(X_i = \"\"<=20\",\"low\",\"married\"\"/Y=0)\n",
    "p_lt20_low_married_nobuy = p_lt20_nobuy*p_low_nobuy*p_married_nobuy\n",
    "#P(X_i = \"\"<=20\",\"medium\",\"students\"\"/Y=0)\n",
    "p_lt20_medium_students_nobuy = p_lt20_nobuy*p_medium_nobuy*p_students_nobuy\n",
    "#P(X_i = \"\"<=20\",\"medium\",\"married\"\"/Y=0)\n",
    "p_lt20_medium_married_nobuy = p_lt20_nobuy*p_medium_nobuy*p_married_nobuy\n",
    "#P(X_i = \"\"<=20\",\"high\",\"students\"\"/Y=0)\n",
    "p_lt20_high_students_nobuy = p_lt20_nobuy*p_high_nobuy*p_students_nobuy\n",
    "#P(X_i = \"\"<=20\",\"high\",\"married\"\"/Y=0)\n",
    "p_lt20_high_married_nobuy = p_lt20_nobuy*p_high_nobuy*p_married_nobuy\n",
    "\n",
    "#P(X_i = \"\"21 to 30\",\"low\",\"students\"\"/Y=0)\n",
    "p_21to30_low_students_nobuy = p_21to30_nobuy*p_low_nobuy*p_students_nobuy\n",
    "#P(X_i = \"\"21 to 30\",\"low\",\"married\"\"/Y=0)\n",
    "p_21to30_low_married_nobuy = p_21to30_nobuy*p_low_nobuy*p_married_nobuy\n",
    "#P(X_i = \"\"21 to 30\",\"medium\",\"students\"\"/Y=0)\n",
    "p_21to30_medium_students_nobuy = p_21to30_nobuy*p_medium_nobuy*p_students_nobuy\n",
    "#P(X_i = \"\"21 to 30\",\"medium\",\"married\"\"/Y=0)\n",
    "p_21to30_medium_married_nobuy = p_21to30_nobuy*p_medium_nobuy*p_married_nobuy\n",
    "#P(X_i = \"\"21 to 30\",\"high\",\"students\"\"/Y=0)\n",
    "p_21to30_high_students_nobuy = p_21to30_nobuy*p_high_nobuy*p_students_nobuy\n",
    "#P(X_i = \"\"21 to 30\",\"high\",\"married\"\"/Y=0)\n",
    "p_21to30_high_married_nobuy = p_21to30_nobuy*p_high_nobuy*p_married_nobuy\n",
    "\n",
    "#P(X_i = \"\">30\",\"low\",\"students\"\"/Y=0)\n",
    "p_gt30_low_students_nobuy = p_gt30_nobuy*p_low_nobuy*p_students_nobuy\n",
    "#P(X_i = \"\">30\",\"low\",\"married\"\"/Y=0)\n",
    "p_gt30_low_married_nobuy = p_gt30_nobuy*p_low_nobuy*p_married_nobuy\n",
    "#P(X_i = \"\">30\",\"medium\",\"students\"\"/Y=0)\n",
    "p_gt30_medium_students_nobuy = p_gt30_nobuy*p_medium_nobuy*p_students_nobuy\n",
    "#P(X_i = \"\">30\",\"medium\",\"married\"\"/Y=0)\n",
    "p_gt30_medium_married_nobuy = p_gt30_nobuy*p_medium_nobuy*p_married_nobuy\n",
    "#P(X_i = \"\">30\",\"high\",\"students\"\"/Y=0)\n",
    "p_gt30_high_students_nobuy = p_gt30_nobuy*p_high_nobuy*p_students_nobuy\n",
    "#P(X_i = \"\">30\",\"high\",\"married\"\"/Y=0)\n",
    "p_gt30_high_married_nobuy = p_gt30_nobuy*p_high_nobuy*p_married_nobuy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(X_{i}= '<=20','low','student'|Y=1) = 0.052478\n",
      "P(X_{i}= '<=20','low','married'|Y=1) = 0.069971\n",
      "P(X_{i}= '<=20','medium','student'|Y=1) = 0.026239\n",
      "P(X_{i}= '<=20','medium','married'|Y=1) = 0.034985\n",
      "P(X_{i}= '<=20','high','student'|Y=1) = 0.104956\n",
      "P(X_{i}= '<=20','high','married'|Y=1) = 0.139942\n",
      "\n",
      "P(X_{i}= '<=20','low','student'|Y=0) = 0.017493\n",
      "P(X_{i}= '<=20','low','married'|Y=0) = 0.023324\n",
      "P(X_{i}= '<=20','medium','student'|Y=0) = 0.087464\n",
      "P(X_{i}= '<=20','medium','married'|Y=0) = 0.116618\n",
      "P(X_{i}= '<=20','high','student'|Y=0) = 0.017493\n",
      "P(X_{i}= '<=20','high','married'|Y=0) = 0.023324\n",
      "\n",
      "P(X_{i}= '21 to 30','low','student'|Y=1) = 0.034985\n",
      "P(X_{i}= '21 to 30','low','married'|Y=1) = 0.046647\n",
      "P(X_{i}= '21 to 30','medium','student'|Y=1) = 0.017493\n",
      "P(X_{i}= '21 to 30','medium','married'|Y=1) = 0.023324\n",
      "P(X_{i}= '21 to 30','high','student'|Y=1) = 0.069971\n",
      "P(X_{i}= '21 to 30','high','married'|Y=1) = 0.093294\n",
      "\n",
      "P(X_{i}= '21 to 30','low','student'|Y=0) = 0.017493\n",
      "P(X_{i}= '21 to 30','low','married'|Y=0) = 0.023324\n",
      "P(X_{i}= '21 to 30','medium','student'|Y=0) = 0.087464\n",
      "P(X_{i}= '21 to 30','medium','married'|Y=0) = 0.116618\n",
      "P(X_{i}= '21 to 30','high','student'|Y=0) = 0.017493\n",
      "P(X_{i}= '21 to 30','high','married'|Y=0) = 0.023324\n",
      "\n",
      "P(X_{i}= '>30','low','student'|Y=1) = 0.034985\n",
      "P(X_{i}= '>30','low','married'|Y=1) = 0.046647\n",
      "P(X_{i}= '>30','medium','student'|Y=1) = 0.017493\n",
      "P(X_{i}= '>30','medium','married'|Y=1) = 0.023324\n",
      "P(X_{i}= '>30','high','student'|Y=1) = 0.069971\n",
      "P(X_{i}= '>30','high','married'|Y=1) = 0.093294\n",
      "\n",
      "P(X_{i}= '>30','low','student'|Y=0) = 0.026239\n",
      "P(X_{i}= '>30','low','married'|Y=0) = 0.034985\n",
      "P(X_{i}= '>30','medium','student'|Y=0) = 0.131195\n",
      "P(X_{i}= '>30','medium','married'|Y=0) = 0.174927\n",
      "P(X_{i}= '>30','high','student'|Y=0) = 0.026239\n",
      "P(X_{i}= '>30','high','married'|Y=0) = 0.034985\n"
     ]
    }
   ],
   "source": [
    "print(\"P(X_{i}= '<=20','low','student'|Y=1) = %f\"%p_lt20_low_students_buy)\n",
    "print(\"P(X_{i}= '<=20','low','married'|Y=1) = %f\"%p_lt20_low_married_buy)\n",
    "print(\"P(X_{i}= '<=20','medium','student'|Y=1) = %f\"%p_lt20_medium_students_buy)\n",
    "print(\"P(X_{i}= '<=20','medium','married'|Y=1) = %f\"%p_lt20_medium_married_buy)\n",
    "print(\"P(X_{i}= '<=20','high','student'|Y=1) = %f\"%p_lt20_high_students_buy)\n",
    "print(\"P(X_{i}= '<=20','high','married'|Y=1) = %f\"%p_lt20_high_married_buy)\n",
    "\n",
    "print(\"\")\n",
    "print(\"P(X_{i}= '<=20','low','student'|Y=0) = %f\"%p_lt20_low_students_nobuy)\n",
    "print(\"P(X_{i}= '<=20','low','married'|Y=0) = %f\"%p_lt20_low_married_nobuy)\n",
    "print(\"P(X_{i}= '<=20','medium','student'|Y=0) = %f\"%p_lt20_medium_students_nobuy)\n",
    "print(\"P(X_{i}= '<=20','medium','married'|Y=0) = %f\"%p_lt20_medium_married_nobuy)\n",
    "print(\"P(X_{i}= '<=20','high','student'|Y=0) = %f\"%p_lt20_high_students_nobuy)\n",
    "print(\"P(X_{i}= '<=20','high','married'|Y=0) = %f\"%p_lt20_high_married_nobuy)\n",
    "print(\"\")\n",
    "print(\"P(X_{i}= '21 to 30','low','student'|Y=1) = %f\"%p_21to30_low_students_buy)\n",
    "print(\"P(X_{i}= '21 to 30','low','married'|Y=1) = %f\"%p_21to30_low_married_buy)\n",
    "print(\"P(X_{i}= '21 to 30','medium','student'|Y=1) = %f\"%p_21to30_medium_students_buy)\n",
    "print(\"P(X_{i}= '21 to 30','medium','married'|Y=1) = %f\"%p_21to30_medium_married_buy)\n",
    "print(\"P(X_{i}= '21 to 30','high','student'|Y=1) = %f\"%p_21to30_high_students_buy)\n",
    "print(\"P(X_{i}= '21 to 30','high','married'|Y=1) = %f\"%p_21to30_high_married_buy)\n",
    "print(\"\")\n",
    "print(\"P(X_{i}= '21 to 30','low','student'|Y=0) = %f\"%p_21to30_low_students_nobuy)\n",
    "print(\"P(X_{i}= '21 to 30','low','married'|Y=0) = %f\"%p_21to30_low_married_nobuy)\n",
    "print(\"P(X_{i}= '21 to 30','medium','student'|Y=0) = %f\"%p_21to30_medium_students_nobuy)\n",
    "print(\"P(X_{i}= '21 to 30','medium','married'|Y=0) = %f\"%p_21to30_medium_married_nobuy)\n",
    "print(\"P(X_{i}= '21 to 30','high','student'|Y=0) = %f\"%p_21to30_high_students_nobuy)\n",
    "print(\"P(X_{i}= '21 to 30','high','married'|Y=0) = %f\"%p_21to30_high_married_nobuy)\n",
    "print(\"\")\n",
    "print(\"P(X_{i}= '>30','low','student'|Y=1) = %f\"%p_gt30_low_students_buy)\n",
    "print(\"P(X_{i}= '>30','low','married'|Y=1) = %f\"%p_gt30_low_married_buy)\n",
    "print(\"P(X_{i}= '>30','medium','student'|Y=1) = %f\"%p_gt30_medium_students_buy)\n",
    "print(\"P(X_{i}= '>30','medium','married'|Y=1) = %f\"%p_gt30_medium_married_buy)\n",
    "print(\"P(X_{i}= '>30','high','student'|Y=1) = %f\"%p_gt30_high_students_buy)\n",
    "print(\"P(X_{i}= '>30','high','married'|Y=1) = %f\"%p_gt30_high_married_buy)\n",
    "print(\"\")\n",
    "print(\"P(X_{i}= '>30','low','student'|Y=0) = %f\"%p_gt30_low_students_nobuy)\n",
    "print(\"P(X_{i}= '>30','low','married'|Y=0) = %f\"%p_gt30_low_married_nobuy)\n",
    "print(\"P(X_{i}= '>30','medium','student'|Y=0) = %f\"%p_gt30_medium_students_nobuy)\n",
    "print(\"P(X_{i}= '>30','medium','married'|Y=0) = %f\"%p_gt30_medium_married_nobuy)\n",
    "print(\"P(X_{i}= '>30','high','student'|Y=0) = %f\"%p_gt30_high_students_nobuy)\n",
    "print(\"P(X_{i}= '>30','high','married'|Y=0) = %f\"%p_gt30_high_married_nobuy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part (d) - Calculating posterior probability of test data point - ('21 to 30', 'medium' , 'married')\n",
    "posterior_buy_xtest = p_21to30_medium_married_buy/(p_21to30_medium_married_buy+p_21to30_medium_married_nobuy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666663\n"
     ]
    }
   ],
   "source": [
    "print(posterior_buy_xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p_{test} = 0.166667$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
